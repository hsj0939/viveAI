import ollama

# ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
model_name = "exaone3.5:2.4b"

# ëŒ€í™” íˆìŠ¤í† ë¦¬ (ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬)
chat_history = []
history_limit = 10  # ìµœëŒ€ 10ê°œë§Œ ìœ ì§€

def ask(question):
    global chat_history

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    chat_history.append({"role": "user", "content": question})

    # íˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œí•œ
    if len(chat_history) > history_limit:
        chat_history = chat_history[-history_limit:]

    # Ollama í˜¸ì¶œ
    response = ollama.chat(
        model=model_name,
        messages=chat_history
    )

    answer = response["message"]["content"].strip()

    # ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ë„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    chat_history.append({"role": "assistant", "content": answer})

    # íˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œí•œ
    if len(chat_history) > history_limit:
        chat_history = chat_history[-history_limit:]

    return answer

if __name__ == "__main__":
    print("ğŸ’¬ Ollama ëŒ€í™” ì‹œì‘ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥)")
    while True:
        q = input("\në‚˜: ")
        if q.lower() in ["exit", "quit", "ì¢…ë£Œ"]:
            print("ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        answer = ask(q)
        print(f"AI: {answer}")


# import ollama

# # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
# model_name = "exaone3.5:2.4b"

# def ask(question):
#     response = ollama.chat(
#         model=model_name,
#         messages=[{"role": "user", "content": question}]
#     )
#     return response["message"]["content"].strip()

# if __name__ == "__main__":
#     q = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
#     answer = ask(q)
#     print("\n=== ë‹µë³€ ===\n")
#     print(answer)
